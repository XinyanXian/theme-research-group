@article{enlighten327323,
 abstract = {Despite the development of various heuristic and machine learning models, social media user occupation predication remains challenging due to limited high-quality ground truth data and difficulties in effectively integrating multiple data sources in different modalities, which can be complementary and contribute to informing the profession or job role of an individual. In response, this study introduces a novel semi-supervised multimodal learning method for Twitter user occupation prediction with a limited number of training samples. Specifically, an unsupervised learning model is first designed to extract textual and visual embeddings from individual tweet messages (textual) and Google Street View images (visual), with the latter capturing the geographical and environmental context surrounding individuals' residential and workplace areas. Next, these high-dimensional multimodal features are fed into a multilayer transfer learning model for individual occupation classification. The proposed occupation prediction method achieves high evaluation scores for identifying Office workers, Students, and Others or Jobless people, with the F1 score for identifying Office workers surpassing the best previously reported scores for occupation classification using social media data.},
 author = {Liu, Xinyi and Peng, Bo and Wu, Meiliu and Wang, Mingshu and Cai, Heng and Huang, Qunying},
 doi = {10.5194/agile-giss-5-36-2024},
 issn = {2700-8150},
 journal = {AGILE: GIScience Series},
 month = {May},
 publisher = {Copernicus Publications},
 title = {Occupation prediction with multimodal learning from Tweet messages and Google Street View images},
 url = {https://eprints.gla.ac.uk/327323/},
 volume = {5},
 year = {2024}
}

